"""
Continuous frame evaluation WITHOUT using weave.Evaluation
This displays image thumbnails in the trace list view
"""

import os
import sys
import asyncio
from pathlib import Path
from dotenv import load_dotenv
import weave
import base64
import io
from PIL import Image
from app.vision import get_vision_analyzer
from app.dataset import get_dataset_loader

# Load environment variables
load_dotenv(dotenv_path=Path(__file__).parent.parent / ".env")


def image_to_data_uri(image_path: str, max_size: int = 150) -> str:
    """Convert image to Data URI for thumbnails"""
    with Image.open(image_path) as img:
        img.thumbnail((max_size, max_size))
        buffer = io.BytesIO()
        img.save(buffer, format='PNG')
        img_bytes = buffer.getvalue()
        img_base64 = base64.b64encode(img_bytes).decode('utf-8')
        return f"data:image/png;base64,{img_base64}"


@weave.op()
async def surgical_vision_model_with_image(input: dict) -> dict:
    """Model function with dict input containing image"""
    analyzer = get_vision_analyzer()
    result = analyzer.analyze_frame(input['image_path'])
    result['input_image'] = input['image']
    result['image_path'] = input['image_path']
    result['frame_id'] = input.get('frame_id', 'unknown')
    return result


async def main():
    # Parse command line arguments
    num_frames = 5  # Default
    video_index = 0  # Default

    if len(sys.argv) > 1:
        try:
            num_frames = int(sys.argv[1])
        except ValueError:
            print("Usage: python test_continuous_frames.py [num_frames] [video_index]")
            print("  num_frames: Number of frames to evaluate (default: 5)")
            print("  video_index: Video index to use (default: 0)")
            sys.exit(1)

    if len(sys.argv) > 2:
        try:
            video_index = int(sys.argv[2])
        except ValueError:
            print("Error: video_index must be an integer")
            sys.exit(1)

    print("ğŸ”¬ Continuous Frame Evaluation (Image Thumbnails in Trace List)")
    print("="*70)
    print(f"Frames to process: {num_frames}")
    print(f"Video index: {video_index}")
    print("="*70)

    # Initialize Weave
    entity = os.getenv("WANDB_ENTITY", "takasi-shibata")
    project = os.getenv("WANDB_PROJECT", "surgical-recap")
    weave.init(f"{entity}/{project}")
    print(f"âœ“ Weave initialized: {entity}/{project}")
    print()

    # Load dataset
    loader = get_dataset_loader()
    if not loader:
        print("âŒ Dataset not found!")
        return

    videos = loader.get_all_videos()

    if video_index >= len(videos):
        print(f"âŒ Video index {video_index} out of range (0-{len(videos)-1})")
        return

    test_video = videos[video_index]
    sequence = loader.load_sequence(test_video, load_images=False)
    frames_to_process = min(num_frames, len(sequence))

    print(f"âœ“ Dataset loaded: {test_video}")
    print(f"âœ“ Processing {frames_to_process} frames")
    if num_frames > len(sequence):
        print(f"âš ï¸  Requested {num_frames} frames, but only {len(sequence)} available")
    print()

    # Get vision analyzer
    analyzer = get_vision_analyzer()
    if not analyzer:
        print("âŒ Vision analyzer not available!")
        return

    print("âœ“ Vision analyzer initialized")
    print()

    # Process frames one by one (NOT using Evaluation)
    print("ğŸš€ Processing frames...")
    print("-"*70)

    results = []
    for i in range(frames_to_process):
        frame = sequence[i]

        # Prepare input with image
        input_dict = {
            "image": image_to_data_uri(frame['image_path'], max_size=150),
            "image_path": frame['image_path'],
            "frame_id": frame['frame_id']
        }

        # Call model
        result = await surgical_vision_model_with_image(input_dict)
        results.append(result)

        print(f"  âœ“ {i+1}/{frames_to_process}: {result['frame_id']} - {result.get('step', 'Unknown')}")

    print("-"*70)
    print()
    print("="*70)
    print("âœ… All frames processed!")
    print("="*70)
    print()
    print(f"ğŸ“Š Processed {len(results)} frames from {test_video}")
    print()
    print("="*70)
    print("ğŸ–¼ï¸  ç”»åƒã‚µãƒ ãƒã‚¤ãƒ«ã®ç¢ºèªæ–¹æ³•")
    print("="*70)
    print()
    print("ã€Tracesãƒšãƒ¼ã‚¸ã§ç¢ºèªï¼ˆç”»åƒã‚µãƒ ãƒã‚¤ãƒ«è¡¨ç¤ºï¼‰ã€‘")
    print(f"   https://wandb.ai/{entity}/{project}/weave/traces")
    print()
    print("   1. ä¸Šã®ãƒªãƒ³ã‚¯ã‚’é–‹ã")
    print("   2. ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã§ 'surgical_vision_model_with_image' ã‚’é¸æŠ")
    print(f"   3. æœ€æ–°ã®{frames_to_process}ã¤ã®ãƒˆãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã®Inputã‚«ãƒ©ãƒ ã«ç”»åƒã‚µãƒ ãƒã‚¤ãƒ«è¡¨ç¤º")
    print()
    print("ğŸ’¡ ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯Evaluationã‚’ä½¿ã‚ãªã„ãŸã‚ã€")
    print("   ãƒˆãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã«ç”»åƒã‚µãƒ ãƒã‚¤ãƒ«ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ï¼")
    print()


if __name__ == "__main__":
    asyncio.run(main())
